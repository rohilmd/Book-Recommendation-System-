{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport implicit\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom scipy.sparse import coo_matrix","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:07.410643Z","iopub.execute_input":"2022-03-19T12:47:07.411261Z","iopub.status.idle":"2022-03-19T12:47:08.312074Z","shell.execute_reply.started":"2022-03-19T12:47:07.411166Z","shell.execute_reply":"2022-03-19T12:47:08.311334Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class Config:\n    #dataset params\n    base_path = '../input/bookcrossing-dataset/Book reviews/Book reviews'\n    users_count = None\n    items_count = None\n    val_data_size = 5\n    typ = 'count'\n    \n    #model params.\n    factors = 200\n    iterations = 20\n    regularization = 0.01\n    show_progress = True\n    \n    N = 1 #number of items to be recommended.","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:09.220297Z","iopub.execute_input":"2022-03-19T12:47:09.220811Z","iopub.status.idle":"2022-03-19T12:47:09.225225Z","shell.execute_reply.started":"2022-03-19T12:47:09.220755Z","shell.execute_reply":"2022-03-19T12:47:09.224554Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"actions_df = pd.read_csv('{}/BX-Book-Ratings.csv'.format(Config.base_path), sep=\";\", encoding='CP1252', escapechar='\\\\')\nusers_df = pd.read_csv('{}/BX-Users.csv'.format(Config.base_path), sep=\";\", encoding='CP1252', escapechar='\\\\')\nitems_df = pd.read_csv('{}/BX_Books.csv'.format(Config.base_path), sep=\";\", encoding='CP1252', escapechar='\\\\')\n\nactions_df.shape, users_df.shape, items_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:11.303254Z","iopub.execute_input":"2022-03-19T12:47:11.303859Z","iopub.status.idle":"2022-03-19T12:47:14.665389Z","shell.execute_reply.started":"2022-03-19T12:47:11.303821Z","shell.execute_reply":"2022-03-19T12:47:14.664654Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#get all the users and items.\nConfig.users_count = users_df['User-ID'].unique().tolist()\nConfig.items_count = items_df['ISBN'].unique().tolist()\n#assign new ids for items by enumerating.\nitems_ids = dict(enumerate(Config.items_count))\nitems_ids = dict([(v, k) for k, v in items_ids.items()])\n#map the new item ids to the existing ones.\nitems_df['Item-ID'] = items_df['ISBN'].map(items_ids)\nactions_df['Item-ID'] = actions_df['ISBN'].map(items_ids)\n#reduce the ids of users by 1.\nusers_df['User-ID'] = users_df['User-ID'] - 1\n# users_df['User-ID'] = users_df['User-ID'].astype(str)\nactions_df['User-ID'] = actions_df['User-ID'] - 1\n# actions_df['User-ID'] = actions_df['User-ID'].astype(str)\nactions_df = actions_df.dropna(axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:14.667088Z","iopub.execute_input":"2022-03-19T12:47:14.667340Z","iopub.status.idle":"2022-03-19T12:47:15.788347Z","shell.execute_reply.started":"2022-03-19T12:47:14.667306Z","shell.execute_reply":"2022-03-19T12:47:15.787573Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def split_dataset(dataset, val_split, typ):\n    ex_count = dataset.shape[0]\n    val_data_size = None\n    \n    if typ == 'percent':\n        val_data_size = int(ex_count*val_split)\n        if val_data_size < 1:\n            raise('Invalid validation split parameter value.')\n    else:\n        val_data_size = val_split\n    \n    data_val = dataset.iloc[ex_count-val_data_size:]\n    data_val.reset_index(drop=True)\n    data_train = dataset.iloc[:ex_count-val_data_size]\n    \n    return data_train, data_val\n\ndef df_to_coo(dataset):\n    user_index = dataset['User-ID'].values\n    item_index = dataset['Item-ID'].values\n    values = dataset['Book-Rating'].values\n    \n    if Config.users_count == None or Config.items_count == None:\n        raise('Not configured properly. Checkout config class.')\n    \n    return coo_matrix(\n        (values, (item_index, user_index)), \n        shape=(len(Config.items_count), len(Config.users_count))\n    )\n\n\ndef prepare_dataset(dataset, val_split=0.05, typ='percent'): #percent and count.\n    data_train, data_val = split_dataset(dataset, val_split, typ)\n    coo_train = df_to_coo(data_train)\n    coo_val = df_to_coo(data_val)\n    return {\n        'train_coo' : coo_train, \n        'train_csr' : coo_train.T.tocsr(),\n        'val_coo' : coo_val,\n        'data_val' : data_val,\n        'data_train' : data_train\n    }\n\ndef train(matrices, factors=100, iterations=10, regularization=0.01, show_progress=True):\n    coo_train = matrices['train_coo']\n    \n    model = implicit.als.AlternatingLeastSquares(factors=factors, \n                                                 iterations=iterations, \n                                                 regularization=regularization, \n                                                 random_state=42)\n    model.fit(coo_train, show_progress=show_progress)\n    \n    return model\n\ndef predict(model, matrices):\n    preds = {}\n    csr_train = matrices['train_csr']\n    items = model.recommend_all(csr_train, N=Config.N, filter_already_liked_items=True)\n    for index, user_id in enumerate(users_df['User-ID'].values):\n        preds[user_id] = items[index]\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:16.180014Z","iopub.execute_input":"2022-03-19T12:47:16.180267Z","iopub.status.idle":"2022-03-19T12:47:16.192504Z","shell.execute_reply.started":"2022-03-19T12:47:16.180239Z","shell.execute_reply":"2022-03-19T12:47:16.191764Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#train\nmatrices = prepare_dataset(actions_df, val_split=Config.val_data_size, typ=Config.typ)\n\nmodel_params = {\n    'factors' : Config.factors,\n    'iterations' : Config.iterations,\n    'regularization' : Config.regularization,\n    'show_progress' : Config.show_progress\n    \n}\nmodel = train(matrices, **model_params)\npreds = predict(model, matrices)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T12:47:19.185155Z","iopub.execute_input":"2022-03-19T12:47:19.185595Z","iopub.status.idle":"2022-03-19T13:00:28.116982Z","shell.execute_reply.started":"2022-03-19T12:47:19.185555Z","shell.execute_reply":"2022-03-19T13:00:28.116231Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"help(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T13:06:18.436715Z","iopub.execute_input":"2022-03-19T13:06:18.437435Z","iopub.status.idle":"2022-03-19T13:06:18.446944Z","shell.execute_reply.started":"2022-03-19T13:06:18.437397Z","shell.execute_reply":"2022-03-19T13:06:18.446073Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}